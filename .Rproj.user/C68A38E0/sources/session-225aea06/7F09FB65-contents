---
title: "Paper supplementary material"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  fig.width = 12,
  fig.height = 8
)
```

```{css, echo = F}
<!-- .header1 { -->
<!-- color: #8a2587; -->
<!-- } -->

.caption {
margin: auto;
text-align: left;
}
```

```{r, warning = F, message = F, include = F, echo = F}
myColour <- "#8a2587"
```

# Introduction

The supplementary material for the lancet paper looking at how different service components effect key clinical outcomes and health care use.
Add in some text to talk about what we're doing in the paper and what this document is going to show

# Library 

These are the packages that were used in the analysis of the data. Please note, the version numbers might be different, but the methods are still the same. 

```{r load libraries, warning = F, message = F}
# packages for analysis and processing
library(tidyverse)
library(tidybayes)
library(brms)
library(lubridate)

# packages for figures and tables in this document 
library(reactable)
library(see)
library(ggridges)
library(icd)
```

```{r figure settings, echo = F}
# Sort out the theme
textSize <- 15:17
theme_set(theme_bw())
theme_update(
  title = element_text(size = textSize[3]),
  axis.text = element_text(size = textSize[2]),
  axis.title = element_text(size = textSize[3]),
  legend.text = element_text(size = textSize[1])
)
```


# Data Linkage 

Data linkage was carried out by eDRIS. Several datasets were linked in order to provide the data necessary to complete the data analysis in this project. 

```{r Show data linkage diagram, echo = F}
knitr::include_graphics("img/LinkageDiagram.jpg")
```

# ICD-10 Codes 

Here is the list of ICD-10 codes used to detect Serious Infections, Cancer, and Cardiovascular events. The codes can be filtered in the table by typing out the key outcome of interest in the space provided. 

<!-- TODO: sort this table to have a word appropriate version of the table -->

```{r sort ICD table, echo = F}
Codes_SI <- c("A01", "A011", "A02", "A020", "A021", "A022", "A028", "A029", "A03", "A033", "A039", 
              "A04", "A044", "A045", "A046", "A047", "A048", "A049", 
              "A15", 
              # "A150", "A152", "A153", # "A156", "A157", "A159", 
              # "A16", # this one is weird since it's just A15 but without confirmation
              # "A162", "A164", "A165", "A169",
              "A170", "A171", "A192", "A199",
              "A270", "A279", "A321", "A327", "A329", "A379", "A390", "A394", "A398", "A400", "A401",
              # "A402", 
              "A403", "A408", "A409", 
              "A41", "A410", # other sepsis
              # "A4100", "A4101", 
              "A4102", 
              # "A4103", "A4109", 
              "A420", "A422", "A428", "A46", "A481", "A483", "A4901", 
              # "A4903", "A4909",
              "A561", "A681", "A692", "A70",
              "B59",
              "G001", "G002", 
              # "G0039", 
              "G008", "G009", "G01", "G01", "G02", "G042", "G060", "G061", "G062", 
              "H600", "H601", "H602", "H603", "H660", "H664", "H669", "H700", "H709", "H730", 
              "I00", "I330", "I339", 
              "J010", "J011", "J012", "J018", "J019", "J020", "J029", "J030", "J039", "J051", "J069", "J13",
              "J14", "J150", "J151", "J152", "J153", "J154", "J155", "J156", "J157", "J158", "J159", 
              "J168", "J180", "J181", "J182", "J188", "J189", "J208", "J209", "J22", "J36", "J390", "J391", "J440",
              "J690", "J698", "J849", "J851", "J852", "J860", "J869", "J950", "J985", "J698", "J849", 
              "K223", "K353", "K358", "K37", "K570", "K571", "K572", "K574", "K610", "K611", "K612", "K613", 
              "K614", "K630", "K631", "K650", "K658", "K659", "K750", "K800", "K803", "K804", "K810", 
              "K811", 
              # "K818", 
              "K819", "K822", "K830", "K832",
              "L010", "L011", "L020", "L021", "L022", "L023", "L024", "L028", "L029", "L030", "L031",
              "L032", "L033", "L038", "L039", "L050", "L080",
              "M000", "M0002", "M0008", "M0080", 
              # "M0090",
              "M009", # This is a code that can be found like the above
              # "M011", 
              "M01",
              # "M4260,
              "M4640", "M650", "M6510",
              "M710", # same as above
              # "M7260", 
              "M726", # same as above
              "M860", "M861", "M8630", "M8640", "M8650", "M8660", 
              # "M8680", "M8690", 
              "M868", "M869", # same as above
              "N10", "N110", "N111", "N118", "N119", "N12", "N136", "N151", "N159", "N300", "N308", "N309", 
              "N340", "N390", "N410", "N431",
              # "N450", "N459",
              "N45", # same as above
              "N481", "N482", "N499", "N61", "N700", "N709", "N711", "N719", 
              "N730", "N731", "N739", "N751", "N760", "N761", "N763", "N764", "N768", 
              "O080", "O2330", "O231", "O233", "O234", "O235", "O239", "O411", "O85","O860", "O861", 
              "O862", 
              # "O863", 
              "O864", "O868", "O911",
              "R572", # this is septic shock... probably quite important to include
              "T814", "T845")


Codes_Cancer <- c("CAN1", "CAN2")


Codes_CVD <- c("I21", "I22", "I252", "I099", "I110", "I130", 
               # "I1320",
               "I132", # same as above
               "I255", "I420", "I425", 
               "I426", "I427", "I428", "I429", "I43", "I50", "P290", "I70", "I71", "I731", "I738", 
               "I739", "I771", "I790", 
               # "I792",
               "I79", # same as above
               "K551", "K558", "K559", "Z958", "Z959", "G45", "G46", 
               "H340", "H341", "I60", "I61", "I62", "I63", 
               # "I64",
               "I65", "I66", "I67", "I68")

thisTable <- tibble(`Outcome Group` = rep(c("Serious Infection", "Cancer", "Cardiovascular Disease"), 
                                          c(length(Codes_SI), length(Codes_Cancer), length(Codes_CVD))), 
                    `ICD-10 Code` = c(Codes_SI, Codes_Cancer, Codes_CVD))


# map_chr(c(thisTable$`ICD-10 Code`), ~{
#   toReturn <- explain_code(.x, condense = F)
#   if(length(toReturn) == 0){
#     return(NA_character_)
#   } else {
#     return(toReturn)
#   }
# })
# thisTable$Description <- explain_code(thisTable$`ICD-10 Code`, condense = F)
thisTable$Description <- sapply(1:nrow(thisTable), function(i){
  explain_code(thisTable$`ICD-10 Code`[i], condense = F)
})

thisTable$Description <- ifelse(thisTable$`ICD-10 Code` == "R572", "Septic Shock", thisTable$Description)

reactable(thisTable, 
          filterable = T, 
          pagination = T,
          highlight = TRUE, 
          showPageSizeOptions = T,
          pageSizeOptions = c(10, 20, 50),
          defaultPageSize = 10)

```

# Analysis 

To demonstrate the analysis carried out in this paper, the results will be use to produce a synthetic dataset. The same model fitting procedures will then be shown alongside additional explanation and extra figures. For the demonstration. I'm only going to look at the Serious Infection data so as to avoid making this document too long. 

## Univariable

This analysis was concerned with looking at the effect of each service component by including each component in separate models adjusting for various demographic features and their 2-way interactions.

```{r read in data for univariate, include = F, echo = F}
df_uni_SI <- read_csv("data/KeyOutcomes/Univariate/SI_SurveyResps.csv")
df_uni_SI <- df_uni_SI %>% 
  mutate(SurveyQ = ifelse(SurveyQ == "GeneralClinic", "CohortedClinic", SurveyQ),
         humanLabel = case_when(
           SurveyQ == "LocalAAVpath" ~ "Local AAV pathway",
           SurveyQ == "LocalGCApath" ~ "Local GCA pathway",
           SurveyQ == "CohortedClinic" ~ "Cohorted clinic",
           SurveyQ == "DiscussMDT" ~ "Any MDT meeting",
           SurveyQ == "VascMDT" ~ "Vasculitis MDT",
           SurveyQ == "OrganSpecialtyMDT" ~ "Local specialty/organ specific MDT only", # Figure out the label for this one
           SurveyQ == "OwnDayCaseUnit" ~ "Own day case unit",
           SurveyQ == "SpecVascNurse" ~ "Specialist vasculitis nurse",
           SurveyQ == "NurseAdviceLine" ~ "Nurse Advice Line", 
           SurveyQ == "NurseLedClinic" ~ "Nurse led clinic",
           SurveyQ == "LocalDatabase" ~ "Local database vasculitis patients",
           SurveyQ == "WaitTimeNewWithinWeek" ~ "Wait time for new patients (<1 week)",
           SurveyQ == "FrequencyFollowUpWithinWeek" ~ "Wait time return patients (<1 week)",
           SurveyQ == "JointParaClinic" ~ "Joint/Parallel clinic",
           SurveyQ == "UrgentIVWithinWeek" ~ "Urgent IV access day case <1 week"
         ))
uniqueQs <- unique(df_uni_SI$SurveyQ)
uniqueLabel <- unique(df_uni_SI$humanLabel)
# Change the label names so they're nicer for people to read 
```
### Figures for Coefficients {.tabset}

For each Service component, a Poisson regression was run while accounting for several demographic features. The results of these models can be seen in the panel below.

```{r function to show the different effects, echo = F, include = F}
showCoefs_tibble <- function(thisData, thisQ, thisLabel, thisColour = "#8a2587"){
  pltData <- thisData[thisData$SurveyQ == thisQ,] %>% 
    filter(Param != "b_Intercept") %>% 
    mutate(Param = str_remove(Param, "b_"), 
           Param = str_remove(Param, "Yes"), 
           order = str_count(Param, ":") * 2, 
           order = ifelse(grepl(thisQ, Param), order - 1, order),
           Param = ifelse(Param == thisQ, thisLabel, Param), 
           Param = fct_reorder(Param, order))
  
  pltData %>% 
    ggplot(aes(Coef, Param)) + 
    geom_vline(xintercept = 0, linetype = "dashed") +
    geom_density_ridges(fill = thisColour, 
                        colour = "transparent", 
                        alpha = .3) + 
    stat_pointinterval(point_interval = "mean_hdci", 
                       colour = thisColour) + 
    scale_x_continuous("", breaks = c(-1, 0, 1)) +
    scale_y_discrete("", limits = rev)
  
}
```

```{r produce tabset for figures, results="asis", echo = FALSE, message = F}
for(i in 1:length(uniqueQs)){
  cat(paste("\n\n#### ", uniqueLabel[i]), "\n ")
  print(
    showCoefs_tibble(df_uni_SI, uniqueQs[i], uniqueLabel[i])
  )
}

```


### Synthetic Data 

Will probably need to do this twice for each dataset.

<!-- ## Multivariate Horseshoe -->
## Multivariable

This analysis included every service component as a term in the model. In doing so, the effect of each service component could be estimated independently of the effect of the other service components. As can be seen below, there are several service components that appear to be highly correlated (i.e., some components are either both present or both absent within a particular service). In addition to entering each service component, a random intercept for a patient's health board of treatment was included to adjust for differences in the base rates of each key clinical outcome and emergency hospital visits. 

TODO: create synthetic data when we have the analysis out of the safehaven. 
<!-- NB: I haven't included the local specialty/organ specific as not everyone provided an answer to that question. So, might want to think about whether or not to include this information? -->

<!-- This section details the process of fitting the model with all service components included with their 2 way interactions only with the demographic information. This approach was opted for in order to estimate which features still appeared to have an impact on outcomes after accounting for the presence of the other service components. The horseshoe prior allows for coefficients to be close to 0 if there is little evidence the effect has much of an impact while allowing larger effects to move away from 0.  -->

<!-- Should show a figure to show the specialties and how the responded to each question to show that we can look at these variables in this way. -->

```{r show survey responses, echo = F, warning = F, message = F}
df_SurveyResps <- read_csv("data/surveyResponses.csv")
# fix GeneralClinic value to be a the cohorted equivalent 
df_SurveyResps <- df_SurveyResps %>% 
  rename(CohortedClinic = GeneralClinic) %>% 
  mutate(CohortedClinic = abs(CohortedClinic - 1))
theseQs <- uniqueQs[uniqueQs %in% colnames(df_SurveyResps)]
df_SurveyResps %>% 
  select(ID, uniqueQs) %>%
  mutate(LedOrAdvice = NurseLedClinic + NurseAdviceLine >= 1) %>% 
  select(-c(OrganSpecialtyMDT, NurseLedClinic, NurseAdviceLine)) %>% 
  gather(2:ncol(.), 
         key = "Question", 
         value = "Response") %>%
  mutate(
    Response = case_when(Response == 1 ~ "Yes",
                         Response == 0 ~ "No", 
                         TRUE ~ "No answer"),
    Response = factor(Response, levels = c("Yes", "No", "No answer")),
    
    humanLabel = case_when(
      Question == "LocalAAVpath" ~ "Local AAV pathway",
      Question == "LocalGCApath" ~ "Local GCA pathway",
      Question == "CohortedClinic" ~ "Cohorted clinic",
      Question == "DiscussMDT" ~ "Any MDT meeting",
      Question == "VascMDT" ~ "Vasculitis MDT",
      Question == "OrganSpecialtyMDT" ~ "Local specialty/organ specific MDT only", # Figure out the label for this one
      Question == "OwnDayCaseUnit" ~ "Own day case unit",
      Question == "SpecVascNurse" ~ "Specialist vasculitis nurse",
      Question == "NurseAdviceLine" ~ "Nurse Advice Line", 
      Question == "NurseLedClinic" ~ "Nurse led clinic",
      Question == "LocalDatabase" ~ "Local database vasculitis patients",
      Question == "WaitTimeNewWithinWeek" ~ "Wait time for new patients (<1 week)",
      Question == "FrequencyFollowUpWithinWeek" ~ "Wait time return patients (<1 week)",
      Question == "JointParaClinic" ~ "Joint/Parallel clinic",
      Question == "UrgentIVWithinWeek" ~ "Urgent IV access day case <1 week",
      Question == "LedOrAdvice" ~ "Nurse advice line and/or led cinic"
    )) %>% 
  ggplot(aes(ID, humanLabel, fill = Response)) + 
  geom_tile(lwd = 1.5, 
            colour = "white", 
            alpha = .7) + 
  scale_x_discrete("") +
  scale_y_discrete("", labels = function(x) str_wrap(x, 20)) +
  scale_fill_manual(values = c("#1a237e", "#b71c1c", "#cfd8dc")) + 
  coord_cartesian(expand = F) + 
  theme_bw() + 
  theme(axis.ticks = element_blank(), 
        legend.position = "bottom", 
        axis.text = element_text(size = min(textSize)),
        legend.text = element_text(size = min(textSize)),
        legend.title = element_text(size = min(textSize)))
ggsave("AllResponses.png", 
       height = 10, 
       width = 17.5)
```

<!-- From the below plot, we can also see that we can see that there are some variables that should only be entered once as they're very strongly related. For example, Vasculitis MDT and Specialist vasculitis nurse are almost entirely the same. The same goes for Nurse led clinic and Nurse Advice line -->

```{r another way to look at things, echo = F, message = F, warning = F, include = F}
# try something where we show how frequently the responses are the same across all pairs?
# Shouldn't be too hard to sort this out?
df_SurveyResps %>% 
  select(ID, uniqueQs) %>% 
  gather(2:ncol(.), 
         key = "QuestionX", 
         value = "ResponseX") %>% 
  left_join(df_SurveyResps %>% 
              select(ID, uniqueQs)) %>% 
  gather(4:ncol(.), 
         key = "QuestionY", 
         value = "ResponseY") %>% 
  drop_na() %>%
  mutate(match = as.numeric(ResponseX == ResponseY)) %>% 
  group_by(QuestionX, QuestionY) %>% 
  summarise(total = n(), 
            sumMatch = sum(match)) %>% 
  ungroup() %>% 
  mutate(prop = sumMatch/total, 
         label = paste0(sumMatch, "/", total, "\n(", round(prop * 100, 2), "%)"), 
         labelCol = prop > .75) %>% 
  ggplot(aes(QuestionX, QuestionY, fill = prop)) + 
  geom_tile(lwd = 1.5, 
            colour = "white") + 
  geom_text(aes(label = label, 
                colour = labelCol)) +
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = .5, 
                       space = "Lab") +
  coord_cartesian(expand = F) + 
  ggtitle("Percentage Agreement") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))
ggsave("AgreementFigure.png",
       height = 10, 
       width = 15)
```

```{r Another way to look at the relationship between responses, echo = F, warning = F, message = F, include = F}
df_SurveyResps %>% 
  select(ID, uniqueQs) %>%
  select(-ID) %>% 
  cor() %>% as_tibble() %>% 
  mutate(QuestionX = colnames(.)) %>% 
  select(QuestionX, everything()) %>% 
  gather(2:ncol(.), 
         key = "QuestionY", 
         value = "Cor") %>% 
  ggplot(aes(QuestionX, QuestionY, fill = Cor)) + 
  geom_tile(lwd = 1.5, 
            colour = "white") + 
  geom_text(aes(label = round(Cor, 3), 
                colour = abs(Cor) > .5)) + 
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = 0, 
                       space = "Lab") +
  coord_cartesian(expand = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))
```

<!-- Another way to look at similarity is the "jaccard" score. Effectively, this treats presence and absence asymmetrically so two absences aren't used in this matching score. Generally this is used when there are a large number of items and 0's a more likely to appear which inflates the similarity in a way that doesn't matter in certain circumstances. Not sure whether the problem we're looking at here needs this solution, but it's worth a look I guess.  -->

```{r test clusteval, echo = F, message = F, include = F}
jaccard_sim <- function(listA, listB){
  bothPos <- sum(listA + listB == 2)
  bothDif <- sum(listA != listB)
  
  return(round(bothPos/(bothPos + bothDif), 3))
}

# Make a figure using the jaccard value... 
# not sure why, but it might be interesting to see? 
# A jaccard index will be better when there are many items and few positive responses
# I don't think we suffer from that problem though? 
# Also, this is a very naive way to compare similarity scores since there are probably some components 
# that mean a service is more similar than another? I know what that means just now, and hopefully will in the future
df_SurveyResps %>% 
  select(ID, uniqueQs) %>% 
  gather(2:ncol(.), 
         key = "QuestionX", 
         value = "ResponseX") %>% 
  left_join(df_SurveyResps %>% 
              select(ID, uniqueQs)) %>% 
  gather(4:ncol(.), 
         key = "QuestionY", 
         value = "ResponseY") %>% 
  drop_na() %>%
  mutate(match = as.numeric(ResponseX == ResponseY)) %>% 
  group_by(QuestionX, QuestionY) %>% 
  mutate(jac = jaccard_sim(ResponseX, ResponseY)) %>% 
  ggplot(aes(QuestionX, QuestionY, fill = jac)) + 
  geom_tile(colour = "white", 
            lwd = 1.5) + 
  geom_text(aes(label = round(jac, 3), 
                colour = abs(jac - .5) > .25)) + 
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = .5, 
                       space = "Lab") +
  coord_cartesian(expand = F) +
  ggtitle("Jaccard score") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))
```


```{r show proportion of each response type, fig.height = 15, fig.width = 13, echo = F, message = F, include = F}
# show how many had both, neither, x not y, y not x
df_SurveyResps %>% 
  select(ID, uniqueQs) %>% 
  gather(2:ncol(.), 
         key = "QuestionX", 
         value = "ResponseX") %>% 
  left_join(df_SurveyResps %>% 
              select(ID, uniqueQs)) %>% 
  gather(4:ncol(.), 
         key = "QuestionY", 
         value = "ResponseY") %>% 
  drop_na() %>% 
  group_by(QuestionX, QuestionY, ResponseX, ResponseY) %>% 
  summarise(n = n()) %>% 
  group_by(QuestionX, QuestionY) %>% 
  mutate(total = sum(n)) %>% 
  ungroup() %>% 
  complete(ResponseX, nesting(QuestionX, QuestionY, ResponseY), fill = list(n = 0)) %>% 
  group_by(QuestionX, QuestionY) %>% 
  mutate(total = sum(n)) %>% 
  ungroup() %>% 
  mutate(prop = n/total, 
         label = paste0("X:", ResponseX, ", Y:", ResponseY, " = ", round(prop * 100, 1), "%\n")) %>% 
  group_by(QuestionX, QuestionY) %>%
  mutate(match = sum(as.numeric(ResponseX == ResponseY) * n)/total) %>% 
  group_by(QuestionX, QuestionY, match) %>% 
  summarise(label = paste(unique(label), collapse = "")) %>% 
  ggplot(aes(QuestionX, QuestionY, fill = match)) + 
  geom_tile(colour = "white", 
            lwd = 1.5 ) + 
  geom_text(aes(label = label, 
                colour = abs(match - .5) > .25)) + 
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = .5, 
                       space = "Lab") +
  coord_cartesian(expand = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))

# TODO add in simple match sumMatch = sum(match)
```

<!-- ### Try different grouping rules for nurses part {.tabset} -->

```{r sort out data for nurse grouping, echo = F, message = F, include = F}
df_NurseCheck <- df_SurveyResps %>% 
  select(ID, uniqueQs) %>% 
  mutate(Nurse3 = as.numeric(SpecVascNurse == 1 & NurseLedClinic == 1 & NurseAdviceLine), 
         Nurse2 = as.numeric((SpecVascNurse + NurseLedClinic + NurseAdviceLine) >= 2),
         Nurse1 = as.numeric((SpecVascNurse + NurseLedClinic + NurseAdviceLine) >= 1)) %>% 
  select(-c(NurseAdviceLine, NurseLedClinic, SpecVascNurse))

NurseCheck <- df_NurseCheck %>% 
  gather(2:ncol(.), 
         key = "QuestionX", 
         value = "ResponseX") %>% 
  left_join(df_NurseCheck) %>% 
  gather(4:ncol(.), 
         key = "QuestionY", 
         value = "ResponseY") %>% 
  drop_na() %>%
  mutate(match = as.numeric(ResponseX == ResponseY)) %>% 
  group_by(QuestionX, QuestionY) %>% 
  summarise(jac = jaccard_sim(ResponseX, ResponseY), 
            simpleMatch = sum(match)/n(), 
            sumAgree = sum(match), 
            total = n())

```


<!-- #### Has all Nurse values  -->

```{r Checking all nurse values, echo = F, message = F, include = F}
NurseCheck %>% 
  filter(QuestionX != "Nurse2", 
         QuestionX != "Nurse1",
         QuestionY != "Nurse2", 
         QuestionY != "Nurse1") %>% 
  ggplot(aes(QuestionX, QuestionY, fill = simpleMatch)) + 
  geom_tile(colour = "white", 
            lwd = 1.5) + 
  geom_text(aes(label = paste0(sumAgree, "/", total, "\n(", round(simpleMatch * 100, 2), "%)"), 
                colour = abs(simpleMatch - .5) > .25)) + 
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = .5, 
                       space = "Lab") +
  coord_cartesian(expand = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))
```

<!-- #### Only missing one  -->

```{r missing one value, echo = F, message = F, include = F}
NurseCheck %>% 
  filter(QuestionX != "Nurse1", 
         QuestionX != "Nurse3",
         QuestionY != "Nurse1", 
         QuestionY != "Nurse3") %>% 
  ggplot(aes(QuestionX, QuestionY, fill = simpleMatch)) + 
  geom_tile(colour = "white", 
            lwd = 1.5) + 
  geom_text(aes(label = paste0(sumAgree, "/", total, "\n(", round(simpleMatch * 100, 2), "%)"), 
                colour = abs(simpleMatch - .5) > .25)) + 
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = .5, 
                       space = "Lab") +
  coord_cartesian(expand = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))
```


<!-- #### Has at least one -->

```{r Has at least one, echo = F, message = F, include = F}
NurseCheck %>% 
  filter(QuestionX != "Nurse2", 
         QuestionX != "Nurse3",
         QuestionY != "Nurse2", 
         QuestionY != "Nurse3") %>% 
  ggplot(aes(QuestionX, QuestionY, fill = simpleMatch)) + 
  geom_tile(colour = "white", 
            lwd = 1.5) + 
  geom_text(aes(label = paste0(sumAgree, "/", total, "\n(", round(simpleMatch * 100, 2), "%)"), 
                colour = abs(simpleMatch - .5) > .25)) + 
  scale_y_discrete("", limits = rev) +
  scale_x_discrete("") +
  scale_colour_manual(values = c("black", "white")) +
  # scale_fill_gradient2(space = "Lab") +
  scale_fill_gradient2(low = "#b71c1c", 
                       mid = "white", 
                       high =  "#1a237e", 
                       midpoint = .5, 
                       space = "Lab") +
  coord_cartesian(expand = F) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "none", 
        axis.text = element_text(size = min(textSize) - 2))
```


### Synthetic Data 

# Data Processing 

## Key Clinical Outcomes

In the above example, the synthetic data was already in a format that worked for the planned analysis. However, the real data had to be processed prior to being entered into the model. For example, inpatient hospital admissions can involve being transferred from one specialty to another. In these instances, a new row is created to represent this visit though it is still part of one continuous stay. This can cause issues for this type of analysis as the number of "_relevant events_" (in this instance Serious Infections that required hospitalisation) can become inflated. To avoid over-counting, a continuous stay marker can be generated to demonstrate whether a row represents part of a previous visit or a brand new admission.

Using this marker, each stay in hospital can be collapsed into one row with all unique ICD-10 codes appearing on the same row in the data. Additional processing involved removing events that occurred within some time window of a previous event to avoid counting the same event multiple times. In this study, a time window of 28 days was selected. 

## Emergency Health Care 

As above, the Emergency care data could include multiple rows that all refer to a single hospital admission. For this analysis, only the first event within a continuous stay was included in the count. Therefore, only the initial reason for the admission was examined. An admission was counted as being an emergency if the admission type fell into one of several categories: 

<!-- 4:8, 30:36, 38:39 -->

- 4: Deliberate Self Injury or Poisoning*
- 5: Road Traffic Accident*
- 6: Home Accident (includes Accidental Poisoning in the home)*
- 7: Other Injury (includes Accidental Poisoning other than in the home)*
- 8: Other (excludes Accidental Poisoning)*
- 30: Emergency Admission - no additional detail
- 31: Patient Injury - Self Inflicted (Injury or Poisoning)
- 32: Patient Injury - Road Traffic Accident
- 33: Patient Injury - Home Incident (incl. assault or accidental poisoning)
- 34: Patient Injury - Incident at Work (incl. assault or accidental poisoning) 
- 35: Patient Injury - Other Injury (incl. assault or accidental poisoning other than in the home or at work) 
- 36: Patient Non-Injury (e.g. Stroke, MI, ruptured appendix)
- 38: Other Emergency Admission (including emergency transfers)
- 39: Emergency Admission - type not known

*NB: Some of the codes included are older codes as the data for this study ranged from 1996 to 2020.


# Anything else?



